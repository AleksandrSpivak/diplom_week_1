Звіт про дослідження: Порівняльний аналіз моделей CV
Цей документ підсумовує етапи дослідження, проведеного в рамках магістерської роботи, від аналізу базового набору даних до двох основних експериментів з порівняння та оптимізації моделей комп'ютерного зору.

1. Аналіз набору даних (Google Open Images V7)
Для дослідження було обрано набір даних Google Open Images Dataset v7.

Масштаб: Містить понад 9 мільйонів зображень.

Тип анотацій: Це multi-label датасет. Зображення мають анотації детекції для 600+ класів об'єктів та анотації рівня зображення (classifications) для тисяч класів.

Релевантність: Датасет містить класи, що безпосередньо відповідають бізнес-категоріям (напр., Wine, Food, Dog, Surfboard, Boat, Castle), що робить його ідеальним для поставленої задачі.

Доступ: Робота з датасетом велася через бібліотеку fiftyone, що дозволило ефективно завантажувати та фільтрувати необхідні зразки.

2. Перший експеримент: Бінарна класифікація та розробка моделі
Метою першого експерименту було оцінити базові SOTA-моделі та розробити кастомний підхід, що задовольняє бізнес-вимоги (висока точність при адекватному охопленні).

2.1. Відбір категорій та класів
Було визначено 4 бізнес-категорії - Catering, Marine_activities, Cultural_Excursions, Pet-Friendly Services. Для кожної категорії було підібрано список відповідних класів-індикаторів з Open Images (напр., для "Catering" це були Wine, Food, Cake тощо). Ця логіка була збережена у файлах available_business_categories.json.

2.2. Формування тестового набору (N x 100/100)
Для кожної бізнес-категорії було створено окремий бінарний датасет:

100 позитивних (true) зображень: Зображення, що гарантовано містять хоча б один клас-індикатор для цієї категорії (напр., "Cat" для "Pet-Friendly").

100 негативних (neg) зображень: Випадкові зображення, що гарантовано не містять жодного класу-індикатора з поточної категорії.

2.3. Робота з моделями
2.3.1. Моделі у фінальному порівнянні - швидкі, пре-трейнед моделі. Це свідомий фокус на цьому сегменті моделей, оскільки навчання моделей на сучасному рівні розвитку датасаєнс вимагає величезних ресурсів, а донавчання чи використання моделей з мілліардами параметрів - значних обчислювальних потужностей. При цьому, бізнес зацікавлений саме в швидких працюючих рішеннях. 
У фінальне порівняння увійшли нвступні моделі:

YOLO (Supervised OD): Помірна точність (P=0.699), але неприйнятно низька повнота (R=0.360).

BLIP (Captioning): Максимальна точність (P=0.972), але провальна повнота (R=0.395).

BLIP (VQA): Хороший баланс (P=0.775) та висока повнота (R=0.813).

Grounding DINO (Zero-shot OD): Висока повнота (R=0.893), але низька точність (P=0.666).

CLIP (Zero-shot): Висока точність (P=0.915), але помірна повнота (R=0.688).

SigLIP (V2 Ensemble): Фінальна розроблена модель, що показала найкращий F1-Score (0.867).

2.3.2. Ітеративна розробка моделі (SigLIP)
Жодна з 5 базових моделей не задовольнила вимоги. Вони були або "сліпими" (низький Recall), або "неточними" (низький Precision). Це призвело до ітеративної розробки кастомного класифікатора на базі SigLIP.

V1 (Fail): Перша спроба з порогом 0.5 провалилася (F1=0.007).

V1 (Tuned): З'ясувалося, що модель вимагає тюнінгу порогу. З threshold=1e-06 було досягнуто F1=0.63, але виявлено низьку повноту (R=0.48) через нерелевантні промпти (що описували сцени замість об'єктів).

V2 (Ensemble) – (Фінальна модель): Розроблено siglip_classifier_v2_ensemble.py. Цей підхід використовував:
Об'єктно-орієнтовані промпти (з available_business_categories.json).
Ансамбль промптів з логікою max(score).
Цей підхід дав найкращий F1-Score (0.867) і одночасно задовольнив бізнес-вимогу (пріоритет точності над реколом при збереженні високого реколу більше або рівного 0.8), показавши Precision = 0.925 при Recall = 0.820.

2.3.3. Моделі, що розглядались, але не були обрані для подальшої роботти
Дані моделі - YOLO, BLIP, DINO, CLIP - увійшли у порівняння, але були відхилені як фінальне рішення. Причина: жодна з них (окрім фінально доопрацьованої SigLIP) не змогла одночасно забезпечити високу точність та прийнятну повноту, що є фундаментальною вимогою бізнес-задачі.

Результати експерименту приведено в наступних таблицях. Для кожної моделі пирведено лише результати найкращої версії.

=================================================================================================
AVERAGE METRICS ACROSS ALL CATEGORIES
=================================================================================================
Model                       F1-Score   Accuracy  Precision     Recall     TP     TN     FP     FN
-------------------------------------------------------------------------------------------------
siglip                        0.8668     0.8750     0.9246     0.8200    328    372     28     72
blip_vqa                      0.7878     0.7850     0.7751     0.8125    325    303     97     75
clip                          0.7825     0.8112     0.9146     0.6875    275    374     26    125
gr_dino                       0.7510     0.6887     0.6662     0.8925    357    194    206     43
blip                          0.5153     0.6913     0.9722     0.3950    158    395      5    242
yolo                          0.4505     0.6700     0.6993     0.3600    144    392      8    256
=================================================================================================

=================================================================================================
TRUE POSITIVES (TP) BY CATEGORY
=================================================================================================
Category                       siglip    blip_vqa        clip     gr_dino        blip        yolo
-------------------------------------------------------------------------------------------------
Catering                           71          92          65          96          49          59
Cultural_Excursions                90          69          59          97          27           0
Marine_Activitiess                 82          72          74          83           8          16
Pet-Friendly Services              85          92          77          81          74          69
=================================================================================================

=================================================================================================
TRUE NEGATIVES (TN) BY CATEGORY
=================================================================================================
Category                       siglip    blip_vqa        clip     gr_dino        blip        yolo
-------------------------------------------------------------------------------------------------
Catering                           92          73          93          63          96          96
Cultural_Excursions                85          80          96           2          99         100
Marine_Activities                  95          85          91          43         100          98
Pet-Friendly Services             100          65          94          86         100          98
=================================================================================================


Evaluating model: yolo
  Catering                  F1=0.7239  Acc=0.7750  P=0.9365  R=0.5900 
  Cultural_Excursions       F1=0.0000  Acc=0.5000  P=0.0000  R=0.0000
  Marine_Activities         F1=0.2712  Acc=0.5700  P=0.8889  R=0.1600 
  Pet-Friendly Services     F1=0.8070  Acc=0.8350  P=0.9718  R=0.6900 

Evaluating model: gr_dino
  Catering                  F1=0.8240  Acc=0.7950  P=0.7218  R=0.9600 
  Cultural_Excursions       F1=0.6576  Acc=0.4950  P=0.4974  R=0.9700
  Marine_Activities         F1=0.6917  Acc=0.6300  P=0.5929  R=0.8300
  Pet-Friendly Services     F1=0.8308  Acc=0.8350  P=0.8526  R=0.8100

Evaluating model: clip
  Catering                  F1=0.7558  Acc=0.7900  P=0.9028  R=0.6500 
  Cultural_Excursions       F1=0.7239  Acc=0.7750  P=0.9365  R=0.5900 
  Marine_Activities         F1=0.8087  Acc=0.8250  P=0.8916  R=0.7400
  Pet-Friendly Services     F1=0.8415  Acc=0.8550  P=0.9277  R=0.7700

Evaluating model: blip
  Catering                  F1=0.6405  Acc=0.7250  P=0.9245  R=0.4900
  Cultural_Excursions       F1=0.4219  Acc=0.6300  P=0.9643  R=0.2700
  Marine_Activities         F1=0.1481  Acc=0.5400  P=1.0000  R=0.0800
  Pet-Friendly Services     F1=0.8506  Acc=0.8700  P=1.0000  R=0.7400

Evaluating model: blip_vqa
  Catering                  F1=0.8402  Acc=0.8250  P=0.7731  R=0.9200 
  Cultural_Excursions       F1=0.7302  Acc=0.7450  P=0.7753  R=0.6900
  Marine_Activities         F1=0.7701  Acc=0.7850  P=0.8276  R=0.7200
  Pet-Friendly Services     F1=0.8106  Acc=0.7850  P=0.7244  R=0.9200

Evaluating model: siglip
  Catering                  F1=0.7933  Acc=0.8150  P=0.8987  R=0.7100 
  Cultural_Excursions       F1=0.8780  Acc=0.8750  P=0.8571  R=0.9000
  Marine_Activities         F1=0.8770  Acc=0.8850  P=0.9425  R=0.8200
  Pet-Friendly Services     F1=0.9189  Acc=0.9250  P=1.0000  R=0.8500

Декілька коментарів по моделях, які не набрали найвищого скору

YOLO (Supervised Object Detection)
Підхід: Використано стандартний підхід Supervised Object Detection. Модель навчалася (або донавчалася) на виявлення конкретних об'єктів з датасету.
Результати: Модель продемонструвала помірну точність (Precision = 0.699). Однак вона мала неприйнятно низьку повноту (Recall = 0.360), пропускаючи значну частину релевантного контенту.
Висновок: Модель була визнана "точною, але сліпою".

BLIP (Image-to-Text Model)
Для BLIP було протестовано два різні підходи:

Підхід 1: Image Captioning (Генерація описів)
Підхід: Модель генерувала текстовий опис для зображення (caption). Потім цей опис аналізувався на наявність ключових слів, пов'язаних з бізнес-категоріями.
Результати: Цей метод дав найвищу точність з усіх (Precision = 0.972). Якщо модель казала, що на фото є бізнес-контент, вона не помилялася. Проте, як і YOLO, вона мала катастрофічно низьку повноту (Recall = 0.395).
Висновок: Також "точний, але сліпий" підхід.

Підхід 2: Visual Question Answering (VQA)
Підхід: Замість генерації описів, моделі ставилося пряме запитання (напр., "Чи є на цьому фото ознаки кейтерингу?").
Результати: Цей підхід дав значно кращий баланс (Precision = 0.775, Recall = 0.813). Він був набагато кращим за Captioning.
Висновок: Хороший баланс, але фінальна модель SigLIP показала кращі результати за F1 та Precision.

Grounding DINO (Zero-shot Object Detection)
Підхід: Використано як Zero-shot детектор об'єктів, якому на вхід подавалися текстові промпти (назви класів) без попереднього навчання на них.
Результати: Модель показала протилежну до YOLO/BLIP проблему. Вона мала чудову повноту (Recall = 0.893), знаходячи майже всі релевантні зображення. Однак вона робила це ціною дуже низької точності (Precision = 0.666), генеруючи багато хибних спрацьовувань.
Висновок: Модель була визнана "всебачачою, але неточною", дуже повільна.

CLIP (Zero-shot Classification)
В ході експерименту було розглянуто декілька підходів:

Підхід CLIP V1 та V2 є об'єктно-орієнтованим мульти-класифікатором. Для кожної категорії він генерує множинні текстові промпти, що відповідають конкретним об'єктам (напр., "a photo of pizza", "a photo of wine"), завантаженим з available_business_categories.json. Відрізнялись формуванням списку класів - базові класи або базові класи плюс розширення кількості класів.

CLIP V3 застосовує сцено-орієнтований, бінарний контрастивний підхід. Він ігнорує окремі об'єкти і порівнює зображення лише з двома промптами: одним позитивним (що описує сцену) та одним специфічним для даної категорії негативним.

CLIP V4 є прямою модифікацією V3, що тестує гіпотезу абстрактного контрасту, замінюючи специфічні негативні промпти на єдиний, універсальний.

Результати: Фінальна версія V4, що увійшла до порівняння (clip), досягла високої точності (Precision = 0.915), але мала лише помірну повноту (Recall = 0.688). Її загальний F1-Score (0.783) був значно перевершений фінальною моделлю SigLIP.


3. наступні кроки 

3.1. 
Другий експеримент: Мультикласова класифікація. Метою другого експерименту буде перевірити найкращу розроблену модель (SigLIP V2) на більш складному та реалістичному "чистому" мультикласовому датасеті.

Модель та датасет
Датасет: Буде створено новий мультикласовий набір даних.
Категорії: 5 класів (4 бізнес-категорії + 1 "Irrelevant").
Розмір: 500 зображень (Support) на кожен клас (загалом 2500 зображень).

Модель: siglip_classifier_v2.py або її аналог для мультикасової клачифікації

3.2. 
Третій експеримент: класифікація синтетичних профілів користувачів соцмедіа. Метою третього експерименту буде перевірити найкращу розроблену модель (SigLIP) на можливість класифікувати профілі користувачів соцмедіа.

Модель та датасет
Датасет: Буде створено новий набір даних, схожих на реальні ситуації. в кожному профілі користувача буде згенеровано від 20 до 40 іміджів за наступним принципом:
Категорії: 
4 класи - любителі певної категорії, кількість іміджів релевантних данній бізнес категоріїї приблизно 50%, інші 50% - інші бізнес категорії, чи нерелевантні іміджі
1 клас -  потенційні користувачі категорії. приблизно по 20% на кожну бізнес-категорію і 20% на нерелевантні іміджі.
1 клас - випадкові користувачі. до 5% на бізнес категорію, 80% - нерелевантного контенту.
1 клас - повністю нерелевантний контент в користувачів.
кількість "користувачів" на категорію потрібно дослідити. Для зручності візуалізації та аналізу результатів планую зробити кількість користувачів одинаковою в кожній категорії.

Кількість профілів на 1 категорію оціночно:
якщо брати 100 профілів на 1 клас, то
7 класів х 100 профілів на 30 (в середньому) іміджів = 21 000 іміджів.

Модель: розроблена на кроці 3.1 або її аналог
